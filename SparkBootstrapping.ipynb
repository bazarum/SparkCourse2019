{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Spark on Colaboratory.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"kvD4HBMi0ohY","colab_type":"text"},"cell_type":"markdown","source":["# Install Java, Spark, and Findspark\n","This installs Apache Spark 2.2.1, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."]},{"metadata":{"id":"fUhBhrGmyAvs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://apache.osuosl.org/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz\n","!tar xf spark-2.2.1-bin-hadoop2.7.tgz\n","!pip install -q findspark"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b4Kjvk_h1AHl","colab_type":"text"},"cell_type":"markdown","source":["# Set Environment Variables\n","Set the locations where Spark and Java are installed."]},{"metadata":{"id":"8Xnb_ePUyQIL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.2.1-bin-hadoop2.7\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"NwU28K5f1H3P","colab_type":"text"},"cell_type":"markdown","source":["# Start a SparkSession\n","This will start a local Spark session."]},{"metadata":{"id":"zgReRGl0y23D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T3ULPx4Y1LiR","colab_type":"text"},"cell_type":"markdown","source":["# Use Spark!\n","That's all there is to it - you're ready to use Spark!"]},{"metadata":{"id":"XJp8ZI-VzYEz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1},{"item_id":2}],"base_uri":"https://localhost:8080/","height":224},"outputId":"fbd1fe8b-c256-4342-d53e-07b63fb20ba8","executionInfo":{"status":"ok","timestamp":1519656068690,"user_tz":300,"elapsed":3742,"user":{"displayName":"Mike Staszel","photoUrl":"//lh6.googleusercontent.com/-x2bxZDh_F-c/AAAAAAAAAAI/AAAAAAAACBg/ERjxLfu8H6E/s50-c-k-no/photo.jpg","userId":"117110509003901457445"}}},"cell_type":"code","source":["df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n","df.show(3)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/spark-2.2.1-bin-hadoop2.7/python/pyspark/sql/session.py:336: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n","  warnings.warn(\"inferring schema from dict is deprecated,\"\n"],"name":"stderr"},{"output_type":"stream","text":["+-----+\n","|hello|\n","+-----+\n","|world|\n","|world|\n","|world|\n","+-----+\n","only showing top 3 rows\n","\n"],"name":"stdout"}]},{"metadata":{"id":"PZkw_gPEQvId","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}